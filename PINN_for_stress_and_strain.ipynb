{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c1a115f-7021-4577-8511-65880b89f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d1a4623-fe3a-4390-8c80-a8173fc41e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "L, W = 1.0, 0.5  # Length and width of the domain (in cm)\n",
    "lambda_ = 5.0e9  # Elastic constant (Pa)\n",
    "mu = 5.0e9       # Shear modulus (Pa)\n",
    "h = 1.0          # Thickness (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3140e2c-7c73-4fcf-9d3c-f092d4673889",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        inputs = torch.cat([x, y], dim=1)\n",
    "        return self.net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd23b82f-5ba3-4fed-90e3-dd61b62f06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain_tensor(u_x, u_y, x, y):\n",
    "    u_x_x = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "    u_y_y = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), retain_graph=True, create_graph=True)[0]\n",
    "    u_x_y = torch.autograd.grad(u_x, y, grad_outputs=torch.ones_like(u_x), retain_graph=True, create_graph=True)[0]\n",
    "    u_y_x = torch.autograd.grad(u_y, x, grad_outputs=torch.ones_like(u_y), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    E_xx = u_x_x\n",
    "    E_yy = u_y_y\n",
    "    E_xy = 0.5 * (u_x_y + u_y_x)\n",
    "    return E_xx, E_yy, E_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1320c02-afc9-4bcb-9ff8-7f1a5d33f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stress_tensor(E_xx, E_yy, E_xy):\n",
    "    trace_E = E_xx + E_yy\n",
    "    sigma_xx = h * (lambda_ * trace_E + 2 * mu * E_xx)\n",
    "    sigma_yy = h * (lambda_ * trace_E + 2 * mu * E_yy)\n",
    "    sigma_xy = h * (2 * mu * E_xy)\n",
    "    return sigma_xx, sigma_yy, sigma_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10abe75f-5883-4f00-a968-0498552e63da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics_loss(model, x, y):\n",
    "    x.requires_grad_(True)\n",
    "    y.requires_grad_(True)\n",
    "    u = model(x, y)\n",
    "    u_x, u_y = u[:, 0:1], u[:, 1:2]\n",
    "\n",
    "    E_xx, E_yy, E_xy = strain_tensor(u_x, u_y, x, y)\n",
    "    sigma_xx, sigma_yy, sigma_xy = stress_tensor(E_xx, E_yy, E_xy)\n",
    "\n",
    "    sigma_xx_x = torch.autograd.grad(sigma_xx, x, grad_outputs=torch.ones_like(sigma_xx), retain_graph=True, create_graph=True)[0]\n",
    "    sigma_xy_y = torch.autograd.grad(sigma_xy, y, grad_outputs=torch.ones_like(sigma_xy), retain_graph=True, create_graph=True)[0]\n",
    "    sigma_yy_y = torch.autograd.grad(sigma_yy, y, grad_outputs=torch.ones_like(sigma_yy), retain_graph=True, create_graph=True)[0]\n",
    "    sigma_xy_x = torch.autograd.grad(sigma_xy, x, grad_outputs=torch.ones_like(sigma_xy), retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "    residual_x = sigma_xx_x + sigma_xy_y\n",
    "    residual_y = sigma_yy_y + sigma_xy_x\n",
    "\n",
    "    loss_equilibrium = torch.mean(residual_x**2 + residual_y**2)\n",
    "    return loss_equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c699cd2-df0e-4be8-9fd7-75c82b36387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundary_condition_loss(model, L, W):\n",
    "    # Boundary A: u_x = 0, u_y = 0 at x = -L/2\n",
    "    y_A = torch.linspace(-W / 2, W / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    u_A = model(-L / 2 * torch.ones_like(y_A), y_A)\n",
    "    loss_A = torch.mean(u_A**2)\n",
    "\n",
    "    # Boundary D: u_x = 0.025 * L, u_y = 0 at x = L/2\n",
    "    y_D = torch.linspace(-W / 2, W / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    u_D = model(L / 2 * torch.ones_like(y_D), y_D)\n",
    "    loss_D = torch.mean((u_D[:, 1:2]**2) + (u_D[:, 0:1] - 0.025 * L)**2)\n",
    "\n",
    "    # Boundary B: traction-free (ﾏダxx = ﾏダxy = 0) at y = W/2\n",
    "    x_B = torch.linspace(-L / 2, L / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    u_B = model(x_B, W / 2 * torch.ones_like(x_B))\n",
    "    u_B_x, u_B_y = u_B[:, 0:1], u_B[:, 1:2]\n",
    "    E_xx_B, E_yy_B, E_xy_B = strain_tensor(u_B_x, u_B_y, x_B, W / 2 * torch.ones_like(x_B))\n",
    "    sigma_xx_B, sigma_yy_B, sigma_xy_B = stress_tensor(E_xx_B, E_yy_B, E_xy_B)\n",
    "    loss_B = torch.mean(sigma_xx_B**2 + sigma_xy_B**2)\n",
    "\n",
    "    # Boundary C: traction-free (ﾏダxx = ﾏダxy = 0) at y = -W/2\n",
    "    x_C = torch.linspace(-L / 2, L / 2, 100).reshape(-1, 1).requires_grad_()\n",
    "    u_C = model(x_C, -W / 2 * torch.ones_like(x_C))\n",
    "    u_C_x, u_C_y = u_C[:, 0:1], u_C[:, 1:2]\n",
    "    E_xx_C, E_yy_C, E_xy_C = strain_tensor(u_C_x, u_C_y, x_C, -W / 2 * torch.ones_like(x_C))\n",
    "    sigma_xx_C, sigma_yy_C, sigma_xy_C = stress_tensor(E_xx_C, E_yy_C, E_xy_C)\n",
    "    loss_C = torch.mean(sigma_xx_C**2 + sigma_xy_C**2)\n",
    "\n",
    "    return loss_A + loss_D + loss_B + loss_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56eb207b-1db8-4a9c-b915-8026c66cbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pinn(model, optimizer, n_epochs, n_points, L, W):\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Sample points inside the domain\n",
    "        x = torch.rand((n_points, 1)) * L - L / 2\n",
    "        y = torch.rand((n_points, 1)) * W - W / 2\n",
    "\n",
    "        loss_pde = physics_loss(model, x, y)\n",
    "        loss_bc = boundary_condition_loss(model, L, W)\n",
    "        loss = loss_pde + loss_bc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf0a632c-0bc8-4a5d-8c95-a0f95518375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1567791980778356736.000000\n",
      "Epoch 500, Loss: 56803098361856.000000\n",
      "Epoch 1000, Loss: 16506323730432.000000\n",
      "Epoch 1500, Loss: 8445418799104.000000\n",
      "Epoch 2000, Loss: 5298567249920.000000\n",
      "Epoch 2500, Loss: 4086950526976.000000\n",
      "Epoch 3000, Loss: 3530405707776.000000\n",
      "Epoch 3500, Loss: 6436942774272.000000\n",
      "Epoch 4000, Loss: 1874246631424.000000\n",
      "Epoch 4500, Loss: 1477950046208.000000\n",
      "Epoch 5000, Loss: 7529187191554048.000000\n",
      "Epoch 5500, Loss: 570156580864.000000\n",
      "Epoch 6000, Loss: 387004891136.000000\n",
      "Epoch 6500, Loss: 322169208832.000000\n",
      "Epoch 7000, Loss: 117146793279488.000000\n",
      "Epoch 7500, Loss: 73428279230464.000000\n",
      "Epoch 8000, Loss: 487275003904.000000\n",
      "Epoch 8500, Loss: 141383811072.000000\n",
      "Epoch 9000, Loss: 68992483328.000000\n",
      "Epoch 9500, Loss: 42430885888.000000\n"
     ]
    }
   ],
   "source": [
    "model = PINN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "n_epochs = 10000\n",
    "n_points = 1000\n",
    "loss_history = train_pinn(model, optimizer, n_epochs, n_points, L, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b066d-fbc9-4a1b-b257-f16fa3f299a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
